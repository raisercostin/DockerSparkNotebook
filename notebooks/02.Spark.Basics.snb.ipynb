{
  "metadata" : {
    "id" : "553e4db3-6bd9-426d-b623-eced20174f2c",
    "name" : "Spark Basics",
    "user_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : null,
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "CDE37C05CD5848ACA579FA84FC23519D"
      },
      "cell_type" : "code",
      "source" : [
        "val a = 1"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "DDB90329FC284E9D80EF42FA267E6D00"
      },
      "cell_type" : "markdown",
      "source" : "### Spark Basics: DataFrames and DataSets"
    },
    {
      "metadata" : {
        "id" : "C7896999DA2C4E6E86B5345E98926B5A"
      },
      "cell_type" : "markdown",
      "source" : "There are three different kinds of data modeling primitives that you can use in a Spark application to keep track of transparently distributed collections:  \n* RDDs (low-level)  \n* DataFrames (conceptually inspired by PyData / Pandas, available in Scala and Python)\n* DataSets (compile-time type-safe DataFrames, available in Scala but not in Python)"
    },
    {
      "metadata" : {
        "id" : "BACB3A90518E448CB946BAE436E10503"
      },
      "cell_type" : "markdown",
      "source" : "To exemplify a use case for DataFrames and DataSets, the first thing we are going to do is to define some input data by hand."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "76AF2B989D474655A69023363225E150"
      },
      "cell_type" : "code",
      "source" : [
        "val rawData: String = \"a,1\\nb,7\\na,4\\nb,3\\na,8\\nb,2\\na,5\\nb,4\\na,7\\na,9\\nb,1\""
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "D0C59C699E7B4B7A9B56B623F5930011"
      },
      "cell_type" : "code",
      "source" : [
        "val dataAfterSplit = rawData.split(\"\\n\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "C5C011457C124BB288B0334806A5B9F2"
      },
      "cell_type" : "code",
      "source" : [
        "dataAfterSplit(0)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "E80C66237AE9486E827F074F380C8506"
      },
      "cell_type" : "markdown",
      "source" : "You'll notice that each record consists of a text key and a numeric value separated by a comma.  \nNext, we define a case class to represent this type of data record."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "BB0E4BBC5E4145599BA66214F1E975FD"
      },
      "cell_type" : "code",
      "source" : [
        "case class DataRecord(key: String, value: Int)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "C55FD23B4B2D4912974B1D6D294C1525"
      },
      "cell_type" : "markdown",
      "source" : "We also define a function to parse our raw CSV records into type-safe **`DataRecord`**s."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "0C9CB55FE51D46E382F3F03C98939860"
      },
      "cell_type" : "code",
      "source" : [
        "def parseIntoDataRecord(s: String): DataRecord = {\n",
        "  val afterSplit = s.split(\",\")\n",
        "  DataRecord( afterSplit(0), afterSplit(1).toInt )\n",
        "}"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "C51F7FA8211A44F18D28C319A5E44A84"
      },
      "cell_type" : "markdown",
      "source" : "Next, we create first a **`DataFrame`** and then a **`DataSet`** based on our data."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "44F63CBA4F7642F98CFFF2C68FAB8716"
      },
      "cell_type" : "code",
      "source" : [
        "val myFirstDataFrame = sparkSession.createDataFrame( dataAfterSplit.map( parseIntoDataRecord(_) ) )"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "44F63CBA4F7642F98CFFF2C68FAB8716"
      },
      "cell_type" : "code",
      "source" : [
        "val myFirstDataSet = myFirstDataFrame.as[DataRecord]"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "9EF577D7E3F94262B6520771F67CE8C3"
      },
      "cell_type" : "markdown",
      "source" : "The data has now been distributed across the Spark cluster, let's have a look at it."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "D070F1331C404072857499E793EA6E0B"
      },
      "cell_type" : "code",
      "source" : [
        "myFirstDataSet.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "EB124C0F0BD846B0978F9DFE81E6AA0D"
      },
      "cell_type" : "code",
      "source" : [
        "myFirstDataSet.count"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "FF6AECEA66C14C9481F1E755A6698349"
      },
      "cell_type" : "markdown",
      "source" : "We can now work with our data using Spark SQL, which is a SQL-2003 compliant language.  \nAll we have to do is attach a table name to our **`DataSet`**."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "9D5730ABE0C343FF8E92007CC5DEC70E"
      },
      "cell_type" : "code",
      "source" : [
        "myFirstDataSet.createOrReplaceTempView(\"raw_data\")\n",
        "\n",
        "println(\"Done.\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "E0C1A3EF83A149439D4CEC6F13D5940A"
      },
      "cell_type" : "code",
      "source" : [
        "sparkSession.sql(\"SELECT key, SUM(value) AS sum_value FROM raw_data GROUP BY key ORDER BY key\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "E0C1A3EF83A149439D4CEC6F13D5940A"
      },
      "cell_type" : "code",
      "source" : [
        "val aggregatedDataFrame = sparkSession.sql(\"SELECT key, SUM(value) AS sum_value FROM raw_data GROUP BY key ORDER BY key\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "A3457856EF3041B584A6F474AC75E970"
      },
      "cell_type" : "code",
      "source" : [
        "val filteredDataFrame = sparkSession.sql(\"SELECT * FROM raw_data WHERE value < 5\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "97FCA97AA0344785BD8500FCF9F9B9BD"
      },
      "cell_type" : "code",
      "source" : [
        "filteredDataFrame"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "44CB275BCC0C4BDB891F69356D4923DE"
      },
      "cell_type" : "markdown",
      "source" : "#### User Defined Functions (UDFs)"
    },
    {
      "metadata" : {
        "id" : "CE224D287CB44EC5AA226EB33A70FC76"
      },
      "cell_type" : "markdown",
      "source" : "User-Defined Functions (UDFs) is a feature of Spark SQL to define new column-based functions.  \nUDFs are very effective because they can be materialized anywhere in the cluster, so the function can be at the same physical location as the data, this makes operating on data using UDFs very efficient."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "2E55962365E84C02937197C91E897566"
      },
      "cell_type" : "code",
      "source" : [
        "// First we define a Scala function\n",
        "def upCaseSqBr(inputStr: String): String = s\"[${inputStr.toUpperCase}]\"\n",
        "\n",
        "println( upCaseSqBr(\"abc\") )"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "9D23502E9CD544C88CC9A8420E0D3CA4"
      },
      "cell_type" : "code",
      "source" : [
        "// Then we register its alias in Spark SQL\n",
        "sparkSession.udf.register[String, String]( \"upCaseSqBrUDF\", upCaseSqBr(_) )"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "41277640E8CA4E6F8DF7C06000AD1A11"
      },
      "cell_type" : "code",
      "source" : [
        "val dataFrameAfterUDF = sparkSession.sql(\"SELECT upCaseSqBrUDF(key) AS up_case_sq_br, value FROM raw_data\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "47911BD5416143F2BC418916CAD6D80B"
      },
      "cell_type" : "code",
      "source" : [
        "dataFrameAfterUDF.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "9F7877FCF5F34CAB8883D027667505E5"
      },
      "cell_type" : "code",
      "source" : [
        "dataFrameAfterUDF.createOrReplaceTempView(\"data_after_udf\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "0E6882AEF10545949CEC00B304D09251"
      },
      "cell_type" : "code",
      "source" : [
        "sparkSession.sql(\"SELECT ROW_NUMBER() OVER(PARTITION BY up_case_sq_br ORDER BY value DESC) as rownum, * FROM data_after_udf\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "0E6882AEF10545949CEC00B304D09251"
      },
      "cell_type" : "code",
      "source" : [
        "sparkSession.sql(\"SELECT ROW_NUMBER() OVER(PARTITION BY up_case_sq_br ORDER BY value DESC) as rownum, * FROM data_after_udf\")\n",
        "            .where('rownum === 1)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "BF7C72E54455478D987E38D18CCC1105"
      },
      "cell_type" : "markdown",
      "source" : "A more realistic example of a UDF is one that generates a UUID."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "370DD36C00154E968305433327279A25"
      },
      "cell_type" : "code",
      "source" : [
        "import java.util.UUID\n",
        "\n",
        "sparkSession.udf.register[String](\"uuid\", () => UUID.randomUUID.toString)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "B3BBCB40DDCD492C86C8094E2DD38A2E"
      },
      "cell_type" : "code",
      "source" : [
        "val dataFrameWithUUID = sparkSession.sql(\"SELECT uuid() AS uuid, * FROM raw_data\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "3F7B63EFD4E54AA98690DF01B4ED17CA"
      },
      "cell_type" : "code",
      "source" : [
        "dataFrameWithUUID.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "E06C50A4A1E94C80836C3B0D4DFDD7A8"
      },
      "cell_type" : "markdown",
      "source" : "#### Joining Two DataSets"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "83AEF9156C054E90801B945831FFB105"
      },
      "cell_type" : "code",
      "source" : [
        ":sh head -5 /opt/SparkDatasets/geography/cities.csv"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "83AEF9156C054E90801B945831FFB105"
      },
      "cell_type" : "code",
      "source" : [
        ":sh cat /opt/SparkDatasets/geography/cities_header.csv"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "AA0136F2F233423BBFD827FE64264021"
      },
      "cell_type" : "code",
      "source" : [
        "case class City (city_id: Long, country_id: Long, city_name: String)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "83AEF9156C054E90801B945831FFB105"
      },
      "cell_type" : "code",
      "source" : [
        ":sh head -5 /opt/SparkDatasets/geography/countries.csv"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "83AEF9156C054E90801B945831FFB105"
      },
      "cell_type" : "code",
      "source" : [
        ":sh cat /opt/SparkDatasets/geography/countries_header.csv"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "C7B476C18049456D8C58FB86E37DFE71"
      },
      "cell_type" : "code",
      "source" : [
        "case class Country (country_id: Long, continent_id: Long, country_name: String)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "543C1675BF194E77868F48603246A550"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.sql.Encoders\n",
        "\n",
        "val citySchema = Encoders.product[City].schema"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "543C1675BF194E77868F48603246A550"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.sql.Encoders\n",
        "\n",
        "val countrySchema = Encoders.product[Country].schema"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "5FAEB99967BC458388F384CA0F4E03F9"
      },
      "cell_type" : "code",
      "source" : [
        "val citiesDS = sparkSession.read.schema(citySchema).csv(\"/opt/SparkDatasets/geography/cities.csv\").as[City]\n",
        "\n",
        "citiesDS.cache\n",
        "\n",
        "citiesDS.createOrReplaceTempView(\"cities\")\n",
        "\n",
        "citiesDS.count"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "5FAEB99967BC458388F384CA0F4E03F9"
      },
      "cell_type" : "code",
      "source" : [
        "val countriesDS = sparkSession.read.schema(countrySchema).csv(\"/opt/SparkDatasets/geography/countries.csv\").as[Country]\n",
        "\n",
        "countriesDS.cache\n",
        "\n",
        "countriesDS.createOrReplaceTempView(\"countries\")\n",
        "\n",
        "countriesDS.count"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "9569C6104B80449BB20CCBEC98EF008F"
      },
      "cell_type" : "code",
      "source" : [
        "sparkSession.sql(\"SELECT countries.country_name, cities.city_name FROM cities INNER JOIN countries ON cities.country_id = countries.country_id\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "099A4F8C553846318A49786DC0B1C6A8"
      },
      "cell_type" : "markdown",
      "source" : "#### Ingesting well-behaved JSON"
    },
    {
      "metadata" : {
        "id" : "8F5F993172774D0384DD566761C24FBA"
      },
      "cell_type" : "markdown",
      "source" : "Given the population data below,  \nand the assumption that zip codes which are close to each other geographically are also close to each other numerically,  \nlet's compute the top 10 list of the most densely populated \"pockets\" of zip codes, along with the U.S. state they are in."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "23C62C362D3B46728BD2984C6A46BB92"
      },
      "cell_type" : "code",
      "source" : [
        ":sh head -5 /opt/SparkDatasets/zipcodes/zips.json"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "630D2D678F0E4F8C9EBD9FCA1880112C"
      },
      "cell_type" : "code",
      "source" : [
        "sparkSession.read.json(\"/opt/SparkDatasets/zipcodes/zips.json\").printSchema"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "73170BDF765D46F584B03F312F41168C"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.sql.Encoders\n",
        "\n",
        "// Define the case class\n",
        "case class PopulationData(city: String, loc: Array[Double], pop: Long, state: String, zip_code: String)\n",
        "\n",
        "// Define the schema\n",
        "val pDataSchema = Encoders.product[PopulationData].schema"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "B377C1F5538C41379C91F98E7C62388B"
      },
      "cell_type" : "code",
      "source" : [
        "// Define the temp view\n",
        "val pDataDS = sparkSession.read.schema(pDataSchema).json(\"/opt/SparkDatasets/zipcodes/zips.json\").as[PopulationData]\n",
        "\n",
        "pDataDS.cache\n",
        "\n",
        "pDataDS.createOrReplaceTempView(\"population_data\")\n",
        "\n",
        "pDataDS.count"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "46EE3EF296DD4DD4B0DA4DDB6FB0112B"
      },
      "cell_type" : "code",
      "source" : [
        "// Define the UDF\n",
        "sparkSession.udf.register[String, String](\"first_four\", _.take(4) )\n",
        "\n",
        "// Write the SQL statement\n",
        "sparkSession.sql(\"\"\"SELECT first_four(zip_code) AS zc_first_four,\n",
        "                           state,\n",
        "                           SUM(pop) AS zone_population\n",
        "                    FROM population_data\n",
        "                    GROUP BY zc_first_four, state\n",
        "                    ORDER BY zone_population DESC\"\"\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "099A4F8C553846318A49786DC0B1C6A8"
      },
      "cell_type" : "markdown",
      "source" : "#### Ingesting real-world JSON"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "A270BF7A1EF94B5FA225B43F2C9615DD"
      },
      "cell_type" : "code",
      "source" : [
        ":sh cat /opt/SparkDatasets/dcos/universe.json"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "A270BF7A1EF94B5FA225B43F2C9615DD"
      },
      "cell_type" : "code",
      "source" : [
        ":sh cat /opt/SparkDatasets/dcos/universe.jsonline"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "193CF5E8EBC240E4A14A38E7F9F2821B"
      },
      "cell_type" : "code",
      "source" : [
        "val alluxio = sparkSession.read.text(\"/opt/SparkDatasets/dcos/universe.jsonline\").first.mkString"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "8219297497AA4C5E81DBFD3EC3D24274"
      },
      "cell_type" : "code",
      "source" : [
        "import org.json4s.native.JsonMethods.parse\n",
        "\n",
        "parse(alluxio)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "10D120555E6D49F99232F0E0C36D0AE7"
      },
      "cell_type" : "code",
      "source" : [
        "// import org.json4s.DefaultFormats\n",
        "\n",
        "// implicit val formats = DefaultFormats"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "61B37E3446F643BC9E3015C8FE01352F"
      },
      "cell_type" : "code",
      "source" : [
        "val (pkgName, pkgContents) =\n",
        "  parse(alluxio).extractOpt[(String,Map[String,Any])]\n",
        "                .getOrElse[(String,Map[String,Any])]( (\"\",Map()) )"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "697D09CF230E43EE89E4384469372780"
      },
      "cell_type" : "code",
      "source" : [
        "case class PackageDownloadCount(packageName: String, month: String, downloadCount: Long)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "presentation" : {
          "tabs_state" : "{\n  \"tab_id\": \"#tab439774947-0\"\n}",
          "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
        },
        "id" : "5AB665EB24AE4065B816DD9CDB018DDA"
      },
      "cell_type" : "code",
      "source" : [
        "pkgContents(\"downloads\").asInstanceOf[Map[String,BigInt]]\n",
        "                        .view\n",
        "                        .map { case (month, downloadCount) => PackageDownloadCount(pkgName, month, downloadCount.longValue) }\n",
        "                        .toSeq"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "44360AADD6174DA99B606485E4E1A8D7"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "B1E8AF5078A9427C8DC8F4D2C595C4F6"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "91B1CB6AA09043FC87C9C1A459D424E5"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "BBEDEBC7F40B4741826CD893281E67A6"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "03C3719BE95542B19A2D6EA37CA26AAF"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "623401FC775648DC816F2734E749898D"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [ ]
    }
  ],
  "nbformat" : 4
}
