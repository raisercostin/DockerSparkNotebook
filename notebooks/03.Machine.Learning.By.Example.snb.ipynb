{
  "metadata" : {
    "id" : "8c622ea0-6a77-452f-9741-227a8e10c899",
    "name" : "Machine Learning By Example",
    "user_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : null,
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "0A15D66CDF064688818C58A9C05EFD42"
      },
      "cell_type" : "code",
      "source" : [
        "val a = 1"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "id" : "74159E15FC714950A356C9926584FB1C"
      },
      "cell_type" : "markdown",
      "source" : "# Machine Learning By Example"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "CEC3B5E5FE61431AB061B98B05E4ECB5"
      },
      "cell_type" : "code",
      "source" : [
        ":sh head -1 /opt/SparkDatasets/topics/abstracts.csv"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "D33A3C8AE5914170802240ADA9E5D56F"
      },
      "cell_type" : "code",
      "source" : [
        "case class LabeledAbstract(track: String, title: String, text: String)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "6838C42C6E6846D28D1C17138FC169A3"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.sql.types.StructType\n",
        "\n",
        "val labeledAbstractSchema: StructType = Encoders.product[LabeledAbstract].schema"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "DC3A5AB80B0D4BCE8F82112BE06540FB"
      },
      "cell_type" : "code",
      "source" : [
        "val inputData: Dataset[LabeledAbstract] =\n",
        "  sparkSession.read\n",
        "              .schema(labeledAbstractSchema)\n",
        "              .option(\"delimiter\", \";\")\n",
        "              .csv(\"/opt/SparkDatasets/topics/abstracts.csv\")\n",
        "              .as[LabeledAbstract]\n",
        "\n",
        "inputData.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "C7C114CF3F9448C18702F83C2881842E"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.feature.{StringIndexer, StringIndexerModel}\n",
        "\n",
        "val stringIndexerModel: StringIndexerModel =\n",
        "  (new StringIndexer).setInputCol(\"track\")\n",
        "                     .setOutputCol(\"indexedLabel\")\n",
        "                     .fit(inputData)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "presentation" : {
          "tabs_state" : "{\n  \"tab_id\": \"#tab940670982-0\"\n}",
          "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [\n    \"string value\"\n  ],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
        },
        "id" : "79DBD2A45A1D40768DB92549F36A0F49"
      },
      "cell_type" : "code",
      "source" : [
        "stringIndexerModel.labels"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "presentation" : {
          "tabs_state" : "{\n  \"tab_id\": \"#tab950169941-0\"\n}",
          "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
        },
        "id" : "79DBD2A45A1D40768DB92549F36A0F49"
      },
      "cell_type" : "code",
      "source" : [
        "stringIndexerModel.labels.zipWithIndex"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "97998E0A48FF4E3186F4E6AE140996EB"
      },
      "cell_type" : "code",
      "source" : [
        "val afterStringIndexer: DataFrame =\n",
        "  stringIndexerModel.transform(inputData)\n",
        "                    .select('indexedLabel, 'title, 'text)\n",
        "\n",
        "afterStringIndexer.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "A61C0F8A53F7407D8558C9CCC887F03A"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.feature.IndexToString\n",
        "\n",
        "val indexToString: IndexToString =\n",
        "  (new IndexToString).setInputCol(\"prediction\")\n",
        "                     .setOutputCol(\"predictionLabel\")\n",
        "                     .setLabels(stringIndexerModel.labels)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "A61C0F8A53F7407D8558C9CCC887F03A"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.feature.SQLTransformer\n",
        "\n",
        "val sqlTransformer: SQLTransformer =\n",
        "  (new SQLTransformer).setStatement(\"\"\"SELECT indexedLabel,\n",
        "                                              concat(title, ' ' , text) AS titleAndText\n",
        "                                       FROM __THIS__\"\"\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "6704220CBE5E4B0CA6F9F1D415AED63D"
      },
      "cell_type" : "code",
      "source" : [
        "val afterSqlTransformer: DataFrame =\n",
        "  sqlTransformer.transform(afterStringIndexer)\n",
        "\n",
        "afterSqlTransformer.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "CC502F485D2E463C8AFA6AB05E8DCF50"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.feature.RegexTokenizer\n",
        "\n",
        "val regexTokenizer: RegexTokenizer =\n",
        "  (new RegexTokenizer).setInputCol(\"titleAndText\")\n",
        "                      .setOutputCol(\"lowercaseTokens\")\n",
        "                      .setPattern(\"\\\\W+\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "7B4179B0694946BC938D0F3918B3513E"
      },
      "cell_type" : "code",
      "source" : [
        "val afterRegexTokenizer =\n",
        "  regexTokenizer.transform(afterSqlTransformer)\n",
        "                .select('indexedLabel, 'lowercaseTokens)\n",
        "\n",
        "afterRegexTokenizer.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "984BAE8894DC4C4381D3739C5C895EC1"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.feature.StopWordsRemover\n",
        "\n",
        "val stopWordsRemover =\n",
        "  (new StopWordsRemover).setInputCol(regexTokenizer.getOutputCol)\n",
        "                        .setOutputCol(\"filteredWords\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "A5BA89D92ED54E0983920529AE52F955"
      },
      "cell_type" : "code",
      "source" : [
        "val afterStopWordsRemover =\n",
        "  stopWordsRemover.transform(afterRegexTokenizer)\n",
        "                  .select('indexedLabel, 'filteredWords)\n",
        "\n",
        "afterStopWordsRemover.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "560ABB85616543A0BCE9CBB4F7F9A10A"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.Transformer\n",
        "import org.apache.spark.ml.util.Identifiable\n",
        "import org.apache.spark.ml.param.ParamMap\n",
        "\n",
        "import org.apache.spark.sql.types.{StructType, StructField, ArrayType, StringType}\n",
        "import org.apache.spark.sql.{DataFrame, Dataset}\n",
        "import org.apache.spark.sql.functions.udf\n",
        "\n",
        "class CustomStemmer(override val uid: String) extends Transformer {\n",
        "  def this() = this(Identifiable.randomUID(\"CustomStemmer\"))\n",
        "\n",
        "  def copy(extra: ParamMap): CustomStemmer = defaultCopy(extra)\n",
        "\n",
        "  override def transformSchema(schema: StructType): StructType = {\n",
        "    schema.add(StructField(\"stemmedWords\", ArrayType(StringType)))\n",
        "  }\n",
        "\n",
        "  override def transform(dset: Dataset[_]): DataFrame = {\n",
        "    import opennlp.tools.stemmer.snowball.SnowballStemmer\n",
        "\n",
        "    val stem = udf {\n",
        "      filteredWords: Seq[String] => {\n",
        "        val opennlpStemmer = new SnowballStemmer(SnowballStemmer.ALGORITHM.ENGLISH)\n",
        "        filteredWords.map(opennlpStemmer.stem(_).toString) }\n",
        "    }\n",
        "    dset.select( dset.col(\"indexedLabel\"), stem(dset.col(\"filteredWords\")).as(\"stemmedWords\") )\n",
        "  }\n",
        "}"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "44344E5BE17C4CE885AE7378904B77D4"
      },
      "cell_type" : "code",
      "source" : [
        "val customStemmer: CustomStemmer = new CustomStemmer"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "E3BF94E358364EED9B8039C534BC20A0"
      },
      "cell_type" : "code",
      "source" : [
        "val afterCustomStemmer =\n",
        "  customStemmer.transform(afterStopWordsRemover)\n",
        "               .select('indexedLabel, 'stemmedWords)\n",
        "\n",
        "afterCustomStemmer.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "3562F867332B4D948DE54D3C600B3B7C"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.feature.NGram\n",
        "\n",
        "val bigramBuilder =\n",
        "  (new NGram).setN(2)\n",
        "             .setInputCol(\"stemmedWords\")\n",
        "             .setOutputCol(\"stemmedWordBigrams\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "FF1D8D8F22A2477A8A8B93F52A69B9A6"
      },
      "cell_type" : "code",
      "source" : [
        "val afterBigramBuilder =\n",
        "  bigramBuilder.transform(afterCustomStemmer)\n",
        "\n",
        "afterBigramBuilder.printSchema\n",
        "\n",
        "afterBigramBuilder.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "27EF76DBC408454D8F8F61C5FED4CE49"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.Transformer\n",
        "import org.apache.spark.ml.util.Identifiable\n",
        "import org.apache.spark.ml.param.ParamMap\n",
        "\n",
        "import org.apache.spark.sql.types.{StructType, StructField, ArrayType, StringType}\n",
        "import org.apache.spark.sql.{DataFrame, Dataset}\n",
        "import org.apache.spark.sql.functions.udf\n",
        "\n",
        "class StemsAndBigramsConcatenator(override val uid: String) extends Transformer {\n",
        "  def this() = this(Identifiable.randomUID(\"StemsAndBigramsConcatenator\"))\n",
        "\n",
        "  def copy(extra: ParamMap): StemsAndBigramsConcatenator = defaultCopy(extra)\n",
        "\n",
        "  override def transformSchema(schema: StructType): StructType = {\n",
        "    schema.add(StructField(\"stemsAndBigrams\", ArrayType(StringType)))\n",
        "  }\n",
        "\n",
        "  override def transform(dset: Dataset[_]): DataFrame = {\n",
        "    val concatenateArrayColumns = udf { (a1: Seq[String], a2: Seq[String]) => a1 ++ a2 }\n",
        "    dset.select( dset.col(\"indexedLabel\"),\n",
        "                 concatenateArrayColumns(dset.col(\"stemmedWords\"), dset.col(\"stemmedWordBigrams\")).as(\"stemsAndBigrams\") )\n",
        "  }\n",
        "}"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "91F460896D984D5B872A09A2F0CE6F99"
      },
      "cell_type" : "code",
      "source" : [
        "val stemsAndBigramsConcatenator: StemsAndBigramsConcatenator = new StemsAndBigramsConcatenator"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "EA525B037226475DAE55CB1928661240"
      },
      "cell_type" : "code",
      "source" : [
        "val afterStemsAndBigramsConcatenator =\n",
        "  stemsAndBigramsConcatenator.transform(afterBigramBuilder)\n",
        "                             .select('indexedLabel, 'stemsAndBigrams)\n",
        "\n",
        "afterStemsAndBigramsConcatenator.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "FA1D3509733444488494F6872BF82899"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.feature.HashingTF\n",
        "\n",
        "val hashingTF =\n",
        "  (new HashingTF).setInputCol(\"stemsAndBigrams\")\n",
        "                 .setOutputCol(\"rawFeatures\")\n",
        "                 .setNumFeatures(32768)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "F81AD33A084749388C0F986A590C5603"
      },
      "cell_type" : "code",
      "source" : [
        "val afterHashingTF =\n",
        "  hashingTF.transform(afterStemsAndBigramsConcatenator)\n",
        "           .select('indexedLabel, 'rawFeatures)\n",
        "\n",
        "afterHashingTF.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "FA1D3509733444488494F6872BF82899"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.feature.IDF\n",
        "\n",
        "val idfModel =\n",
        "  (new IDF).setInputCol(\"rawFeatures\")\n",
        "           .setOutputCol(\"features\")\n",
        "           .fit(afterHashingTF)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "F81AD33A084749388C0F986A590C5603"
      },
      "cell_type" : "code",
      "source" : [
        "val afterIDF =\n",
        "  idfModel.transform(afterHashingTF)\n",
        "          .select('indexedLabel, 'features)\n",
        "\n",
        "afterIDF.cache"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "3188F9B0899D49798FCDD7FC859E9315"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.classification.NaiveBayes\n",
        "\n",
        "val naiveBayes =\n",
        "  (new NaiveBayes).setLabelCol(\"indexedLabel\")\n",
        "                  .setFeaturesCol(\"features\")\n",
        "                  .setSmoothing(1.0)\n",
        "                  .setModelType(\"multinomial\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "3188F9B0899D49798FCDD7FC859E9315"
      },
      "cell_type" : "code",
      "source" : [
        "// import org.apache.spark.ml.classification.RandomForestClassifier\n",
        "\n",
        "// val randomForest =\n",
        "//   (new RandomForestClassifier).setLabelCol(\"indexedLabel\")\n",
        "//                               .setFeaturesCol(\"features\")\n",
        "//                               .setNumTrees(157)\n",
        "//                               .setMaxDepth(29)\n",
        "//                               .setSeed(1234L)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "4CFA0C2DE857487F82641B5641646514"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.Pipeline\n",
        "\n",
        "val pipeline =\n",
        "  (new Pipeline).setStages(Array(stringIndexerModel,\n",
        "                                 sqlTransformer,\n",
        "                                 regexTokenizer,\n",
        "                                 stopWordsRemover,\n",
        "                                 customStemmer,\n",
        "                                 bigramBuilder,\n",
        "                                 stemsAndBigramsConcatenator,\n",
        "                                 hashingTF,\n",
        "                                 idfModel,\n",
        "                                 naiveBayes,\n",
        "                                 indexToString))"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "3D299022858544278E73BFE19E498B96"
      },
      "cell_type" : "code",
      "source" : [
        "val Array(trainData, testData) = inputData.randomSplit(Array(0.6, 0.4), seed = 1234L)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "BFAB79B0CDC54B2494282C365488AA86"
      },
      "cell_type" : "code",
      "source" : [
        "val model = pipeline.fit(trainData)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "88B1979840294889A8CB12ACCDB871E9"
      },
      "cell_type" : "code",
      "source" : [
        "val trainPredictions = model.transform(trainData)\n",
        "\n",
        "trainPredictions.printSchema"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "4AF7D5B2242144F48494B361FEF2E859"
      },
      "cell_type" : "code",
      "source" : [
        "val testPredictions = model.transform(testData)\n",
        "\n",
        "testPredictions.select('prediction, 'indexedLabel)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "3F47362AFCE748ABB2283F160AAEEB6F"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
        "\n",
        "val evaluator =\n",
        "  (new MulticlassClassificationEvaluator).setLabelCol(\"indexedLabel\")\n",
        "                                         .setPredictionCol(\"prediction\")\n",
        "                                         .setMetricName(\"accuracy\")"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "27BB21E4BA1542468F36461201ED7AD6"
      },
      "cell_type" : "code",
      "source" : [
        "val trainAccuracy = evaluator.evaluate(trainPredictions)\n",
        "val testAccuracy = evaluator.evaluate(testPredictions)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "55B2DFA7351C45E9993DD9A1D6E6EF84"
      },
      "cell_type" : "code",
      "source" : [
        "val newAbstractTitle = \"Microservices Deployment on the AWS Cloud\"\n",
        "\n",
        "val part1 = \"You will see how continuous deployment of microservices on the AWS platform\"\n",
        "val part2 = \"is performed in a repeatable and reliable fashion\"\n",
        "val part3 = \"with an emphasis on reliability, scalability, monitoring, and security\"\n",
        "\n",
        "val newAbstractText = s\"${part1} ${part2} ${part3}\"\n",
        "\n",
        "val newObservation =\n",
        "  sparkSession.createDataFrame( Seq( (999, newAbstractTitle, newAbstractText) ) )\n",
        "              .toDF(\"indexedLabel\", \"title\",\"text\")\n",
        "\n",
        "model.transform(newObservation).select('predictionLabel, 'stemsAndBigrams)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "9ED9412694AC45188C8476880CEE34B5"
      },
      "cell_type" : "code",
      "source" : [
        "val newAbstractTitle = \"Machine Learning At Scale With Spark\"\n",
        "\n",
        "val newAbstractText = \"This talk is for aspiring data scientists\"\n",
        "\n",
        "val newObservation =\n",
        "  sparkSession.createDataFrame( Seq( (999, newAbstractTitle, newAbstractText) ) )\n",
        "              .toDF(\"indexedLabel\", \"title\",\"text\")\n",
        "\n",
        "model.transform(newObservation).select('predictionLabel, 'stemsAndBigrams)"
      ],
      "outputs" : [ ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "F8876C1E520C47258073154F39F47131"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [ ]
    }
  ],
  "nbformat" : 4
}